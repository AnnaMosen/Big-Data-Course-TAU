{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the target directory exist in Hadoop and if so, delete it, then create it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19/06/12 23:07:20 INFO fs.TrashPolicyDefault: Moved: 'hdfs://bdl0.eng.tau.ac.il:8020/user/stud22/hw2' to trash at: hdfs://bdl0.eng.tau.ac.il:8020/user/stud22/.Trash/Current/user/stud22/hw2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "target_dir=/user/stud22/hw2\n",
    "hadoop fs -test -d ${target_dir}\n",
    "if [ $? -eq 0 ]\n",
    "then\n",
    "    hdfs dfs -rm -r /user/stud22/hw2\n",
    "    hdfs dfs -mkdir /user/stud22/hw2\n",
    "else\n",
    "    hdfs dfs -mkdir /user/stud22/hw2\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the relevant directory was created and it's empty now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -ls /user/stud22/hw2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the data files to Hadoop into the directory we justed created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -put /home/stud22/bigdata_lab/microsoft-com.data/ /user/stud22/hw2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure the files were copied to Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V,42710,1001,1\n",
      "V,42710,1018,1\n",
      "V,42711,1008,1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -cat /user/stud22/hw2/microsoft-com.data/microsoft-com.data | tail -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the files have been successfully copied to HDFS, we can start working with spark to analyze them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7fcd00081d90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pandas as pd\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98948"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data to an RDD\n",
    "msData = sc.textFile(\"hdfs:/user/stud22/hw2/microsoft-com.data/microsoft-com.data\")\n",
    "msData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the countries file to and RDD and store it in a Python list\n",
    "countriesRdd = sc.textFile(\"hdfs:/user/stud22/hw2/microsoft-com.data/countries.txt\")\n",
    "countries=countriesRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataLineMap(record):\n",
    "    record=record.replace('\"','')\n",
    "    return record.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'A', u'1287', u'1', u'International AutoRoute', u'/autoroute'],\n",
       " [u'A', u'1288', u'1', u'library', u'/library'],\n",
       " [u'A', u'1289', u'1', u'Master Chef Product Information', u'/masterchef']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the attribute lines from the msData rdd and remove the \" character\n",
    "attributesRdd=msData.filter(lambda record: record[0]=='A').map(dataLineMap)\n",
    "attributesRdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98654"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the attribute lines from the msData rdd and remove the \" character\n",
    "votesRdd=msData.filter(lambda record: record[0]=='V').map(dataLineMap)\n",
    "votesRdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'V', u'10001', u'1000', u'1'],\n",
       " [u'V', u'10001', u'1001', u'1'],\n",
       " [u'V', u'10001', u'1002', u'1']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votesRdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a dictionary of the sites that match the countries by the site id\n",
    "countrySites=attributesRdd.filter(lambda record: record[3] in countries)\\\n",
    "                              .map(lambda record: (record[1],record[3])).collect()\n",
    "countrySitesDict=dict(countrySites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3334"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the users that visited the country sites\n",
    "countryUsersVotesRdd=votesRdd.filter(lambda record: record[2] in countrySitesDict)\n",
    "#Create a list of these users' ids\n",
    "countryUsersList=countryUsersVotesRdd.map(lambda record: record[1]).collect()\n",
    "#Remove users that appear twice (remove duplicates)\n",
    "countryUsersList = list(dict.fromkeys(countryUsersList))\n",
    "countryUsersVotesRdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'V', u'10004', u'1005', u'1'],\n",
       " [u'V', u'10014', u'1023', u'1'],\n",
       " [u'V', u'10035', u'1053', u'1']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countryUsersVotesRdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Norway-10004', 1), (u'Spain-10014', 1), (u'Jakarta-10035', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a map to create (country-user,1) pairs to reduce in the next steps\n",
    "countryVisitPairRdd = countryUsersVotesRdd.map(lambda record: (countrySitesDict[record[2]]+'-'+record[1],1))\n",
    "countryVisitPairRdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if a \"number_of_users_by_country\" directory exists, if it does, delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "target_dir=/user/stud22/hw2/number_of_users_by_country\n",
    "hadoop fs -test -d ${target_dir}\n",
    "if [ $? -eq 0 ]\n",
    "then \n",
    "    hdfs dfs -rm -r /user/stud22/hw2/number_of_users_by_country\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jakarta</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UK</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>France</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Italy</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Australia</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Canada</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Korea</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Russia</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Norway</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Poland</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Israel</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Finland</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>China</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hungary</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Slovakia</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>India</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Slovenija</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Caribbean</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Chile</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Uruguay</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Peru</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0    1\n",
       "0          Jakarta  670\n",
       "1          Germany  372\n",
       "2           Sweden  258\n",
       "3           Taiwan  204\n",
       "4            Spain  191\n",
       "5               UK  186\n",
       "6           France  183\n",
       "7            Italy  167\n",
       "8        Australia  136\n",
       "9           Canada  128\n",
       "10          Brazil  121\n",
       "11           Korea   94\n",
       "12         Denmark   55\n",
       "13          Russia   52\n",
       "14         Belgium   45\n",
       "15          Norway   42\n",
       "16          Poland   38\n",
       "17       Hong Kong   35\n",
       "18          Israel   34\n",
       "19          Mexico   33\n",
       "20       Argentina   32\n",
       "21     Switzerland   31\n",
       "22         Finland   29\n",
       "23           China   26\n",
       "24    South Africa   19\n",
       "25  Czech Republic   16\n",
       "26        Portugal   15\n",
       "27         Hungary   15\n",
       "28         Ireland   13\n",
       "29        Slovakia   11\n",
       "30        Colombia   11\n",
       "31        Thailand   11\n",
       "32     New Zealand   10\n",
       "33          Turkey    9\n",
       "34           India    9\n",
       "35       Slovenija    9\n",
       "36       Venezuela    8\n",
       "37       Caribbean    5\n",
       "38           Chile    4\n",
       "39         Uruguay    4\n",
       "40            Peru    3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Take the (country-user,1) map, reduce it, than map it again to (country,1) reduce again, and print it\n",
    "countryUserVistsRdd=countryVisitPairRdd.reduceByKey(lambda v1,v2: v1+v2).map(lambda record: (record[0].split('-')[0],1))\\\n",
    "                                      .reduceByKey(lambda v1,v2: v1+v2)\\\n",
    "                                      .sortBy(lambda record: record[1]*-1)\n",
    "countryUserVistsRdd.map(lambda record: record[0]+':'+str(record[1]))\\\n",
    "                   .saveAsTextFile(\"hdfs:/user/stud22/hw2/number_of_users_by_country\")\n",
    "df = pd.DataFrame(countryUserVistsRdd.collect())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that a file was created and its content is in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jakarta:670\n",
      "Germany:372\n",
      "Sweden:258\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -cat /user/stud22/hw2/number_of_users_by_country/part-00000 | head -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jakarta</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1\n",
       "0  Jakarta  670\n",
       "1  Germany  372\n",
       "2   Sweden  258\n",
       "3   Taiwan  204\n",
       "4    Spain  191"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Take the (country,1) map, reduce it, sort it, and print the top 5\n",
    "countryByVisitsRdd=countryVisitPairRdd.map(lambda record: (record[0].split('-')[0],1))\\\n",
    "                                      .reduceByKey(lambda v1,v2: v1+v2).sortBy(lambda record: record[1]*-1)\n",
    "df = pd.DataFrame(countryByVisitsRdd.take(5))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the data is the same, that's because no user visited a country's site twice (so counting users visits per country vs total visits per country result in the same number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduceAverage(v1,v2):\n",
    "    amount1=float(v1[0])\n",
    "    count1=float(v1[1])\n",
    "    amount2=float(v2[0])\n",
    "    count2=float(v2[1])\n",
    "    amount=(amount1*count1+amount2*count2)/(count1+count2)\n",
    "    return (amount,count1+count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Avg', (3.0159273638837134, 32711.0))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all the votes, map them (user_id,1) then reduce by the user_id, so we get the number of pages visited by\n",
    "#each user. Then take the resulting RDD and map it to ('Avg',(pages_visited,1)) pairs, then reduce by the\n",
    "#key (which is \"Avg\", the result will be 1 line with the average and the count of users)\n",
    "usersViewsRdd=votesRdd.map(lambda record: (record[1],1))\\\n",
    "                                           .reduceByKey(lambda v1,v2: v1+v2)\n",
    "usersAverageRdd=usersViewsRdd.map(lambda record: ('Avg',(record[1],1))).reduceByKey(reduceAverage)\n",
    "usersAverageRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduceMax(v1,v2):\n",
    "    if int(v1)>=int(v2):\n",
    "        return int(v1)\n",
    "    return int(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Max', 35)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take the usersViewRDD that we created in the previous step, map to (\"Max\",pages_visited) pairs and reduce by\n",
    "#the key (which is \"Max\", the result will be 1 line with the max visits)\n",
    "usersMaxRdd=usersViewsRdd.map(lambda record: ('Max',record[1])).reduceByKey(reduceMax)\n",
    "usersMaxRdd.collect()              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the directory we created in Hadoop (and all the files and sub directories in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: `/user/stud22/hw2/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -rm -r /user/stud22/hw2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll check to verify the directory no longer exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: `/users/studd22/hw2': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -ls /users/studd22/hw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark2(2.1.0)",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
